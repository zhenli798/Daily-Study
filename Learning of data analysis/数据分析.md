# 数据分析实战学习笔记

## 1. 数据分析组成部分

1. **数据采集**
2. **数据挖掘**
3. **数据可视化**

## 2. 数据挖掘

### 2.1 数据挖掘的步骤

1. **商业理解**：从商业的角度理解项目需求，然后再对数据挖掘的目标进行定义。
2. **数据理解**：尝试收集部分数据，然后对数据进行探索，包括数据描述、数据质量验证等。
3. **数据准备**：开始收集数据，并对数据进行清洗、数据集成等操作。
4. **模型建立**：选择和应用各种数据挖掘模型，并进行优化，以便得到更好的分类结果。
5. **模型评估**：对模型进行评价，并检查构建模型的每个步骤，确认模型是否实现了预定的商业目标。
6. **上线发布**

### 2.2 数据挖掘的十大算法

* 由国际权威的学术组织ICDM评选得到。
* **按照不同的目的分为四类**：
  * 分类算法：C4.5，朴素贝叶斯，SVM，KNN，Adaboost，CART
  * 聚类算法：K-Means，EM
  * 关联分析：Apriori
  * 连接分析：PageRank

### 2.3 数据挖掘需要具备的数学基础

* 概率论
* 线性代数
* 图论
* 最优化方法

## 3. Python引用

**引用模块/包**：**import**

```python

# 导入一个模块
import model_name
# 导入多个模块
import module_name1,module_name2
# 导入包中指定模块 
from package_name import moudule_name
# 导入包中所有模块 
from package_name import *
```

## 4. NumPy库

### 4.1 为什么要用NumPy而不用list?

答：在Python中list的元素在内存中的存储是分散的，而NumPy数据是存储在一个均匀连续的内存块中。这样数组计算遍历所有的元素，不像列表list还需要对内存地址进行查找，从而节省计算资源。并且在调用数据时，CPU可以利用矢量化功能调用内存中的整块NumPy数据，且NumPy的数据支持CPU的多线程处理。

### 4.2 NumPy里两个重要的对象

1. **ndarray(N-dimensional array object)**：

   * 作用：解决多维数组问题

   * 前言：在NumPy数组中，维数称为秩(rank)，一维数组的秩为1，二维数组的秩为2，以此类推。在NumPy中，每一个线性的数组称为一个轴(axes)，其实秩就是描述轴的数量。

   * 使用：

     * 创建数组：

       ```python
       import numpy as np
       a = np.array([1, 2, 3])
       b = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
       print(b)
       b[1, 1] = 10
       print(b)
       print(a.shape)
       print(b.shape)
       print(a.dtype) # 查看a矩阵中数据的类型
       ```

       运行结果：

       ```python
       [[1 2 3]
        [4 5 6]
        [7 8 9]]
       [[ 1  2  3]
        [ 4 10  6]
        [ 7  8  9]]
       (3,)
       (3, 3)
       int32
       ```

     * 结构数组：

       * 跟c语言中的结构体类似

       ```python
       import numpy as np
       persontype = np.dtype({
           'names' : ['name', 'age', 'chinese', 'math', 'english'],
           'formats' : ['S32', 'i', 'i', 'i', 'f']})
       peoples = np.array([("ZhangFei", 32, 75, 100, 90), ("GuanYu", 24, 85, 96, 88.5), ("ZhaoYun", 28, 85, 92, 96.5), ("HuangZhong", 29, 65, 85, 100)], dtype = persontype)
       ages = peoples[:]['age']
       chineses = peoples[:]['chinese']
       maths = peoples[:]['math']
       englishs = peoples[:]['english']
       print(np.mean(ages)) # mean是求平均值
       print(np.mean(chineses))
       print(np.mean(maths))
       print(np.mean(englishs))
       ```

       运行结果：

       ```python
       28.25
       77.5
       93.25
       93.75
       ```

       

2. **ufunc(universal function object)**：

   * 作用：解决对数组进行处理的函数

   * 使用：

     * 连续数组的创建：

       ```python
       x1 = np.arange(1, 11, 2)
       x2 = np.linspace(1, 9, 5)
       print(x1)
       print(x2)
       ```

       运行结果：

       ```python
       [1 3 5 7 9]
       [1. 3. 5. 7. 9.]
       ```

       总结：忽略数据类型的话，结果都是1，3，5，7，9，但两者的创建方式是不同的。

       * arange()类似内置函数range()，通过指定**初始值、终值、步长**来创建等差数列的一维数组，默认是不包括终值。
       * linspace是linear space的缩写，代表线性等分向量的含义。linspace()通过指定**初始值、终值、元素**个数来创建等差数列的一维数组，默认是包括终值的。

     * 算数运算：

       * 进行加、减、乘、除、求n次方和取余数

       ```python
       x1 = np.arange(1, 11, 2)
       x2 = np.linspace(1, 9, 5)
       print(np.add(x1, x2)) # 加
       print(np.subtract(x1, x2)) # 减
       print(np.multiply(x1, x2)) # 乘
       print(np.divide(x1, x2)) # 除
       print(np.power(x1, x2)) # 求n次方
       print(np.remainder(x1, x2)) # 取余数，np.mod(x1, x2)也是
       ```

       运行结果：

       ```python
       [ 2.  6. 10. 14. 18.]
       [0. 0. 0. 0. 0.]
       [ 1.  9. 25. 49. 81.]
       [1. 1. 1. 1. 1.]
       [1.00000000e+00 2.70000000e+01 3.12500000e+03 8.23543000e+05
        3.87420489e+08]
       [0. 0. 0. 0. 0.]
       ```

     * 统计函数

       * 计算数组/矩阵中的最大值函数amax()，最小值函数amin()

       ```python
       import numpy as np
       a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
       print(np.amin(a))
       print(np.amin(a, 0)) # 0代表找每一列最小值
       print(np.amin(a, 1)) # 1代表找每一行最小值
       print(np.amax(a))
       print(np.amax(a, 0)) # 找每一列最大值
       print(np.amax(a, 1)) # 找每一行最大值
       ```

       运行结果：

       ```python
       1
       [1 2 3]
       [1 4 7]
       9
       [7 8 9]
       [3 6 9]
       ```

       * 统计最大值与最小值之差ptp()

       ```python
       a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
       print(np.ptp(a))
       print(np.ptp(a, 0)) # 找每一列最大值跟最小值之差
       print(np.ptp(a, 1)) # 找每一行最大值跟最小值之差
       ```

       运行结果：

       ```python
       8
       [6 6 6]
       [2 2 2]
       ```

       * 统计数组的百分位数percentile()

       ```python
       # 统计数组的百分位数
       a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
       print(np.percentile(a, 50)) # 第二个参数代表p，p的取值范围是0-100，如果p=0.那么是求最小值，p=50就是求平均值，p=100就是求最大值
       print(np.percentile(a, 50, axis = 0))
       ```

       运行结果：

       ```python
       5.0
       [4. 5. 6.]
       [2. 5. 8.]
       ```

       * 统计数组中的中位数median()、平均数mean()

       ```python
       a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
       # 求中位数
       print(np.median(a))
       print(np.median(a, axis = 0))
       print(np.median(a, axis = 1))
       # 求平均数
       print(np.mean(a))
       print(np.mean(a, axis = 0))
       print(np.mean(a, axis = 1))
       ```

       运行结果：

       ```python
       5.0
       [4. 5. 6.]
       [2. 5. 8.]
       5.0
       [4. 5. 6.]
       [2. 5. 8.]
       ```

       * 统计数组中的加权平均值average()

       ```python
       # 统计数组中的加权平均值
       a = np.array([1, 2, 3, 4])
       wts = np.array([1, 2, 3, 4])
       print(np.average(a)) # （1 + 2 + 3 + 4)/4 = 2.5,默认情况下权重每个元素都是1
       print(np.average(a, weights = wts)) # (1 * 1 + 2 * 2 + 3 * 3 + 4 * 4)/(1 + 2 + 3 + 4) = 3.0
       ```

       * 统计数组中的标准差std()、方差var()

         方差的计算是指每个数值与平均值之差的平方求和的平均值

         即`mean((x - x.mean())**2)`

       ```python
       a = np.array([1, 2, 3, 4])
       print(np.std(a)) # 求这组数据的标准差
       print(np.var(a)) # 求这组数据的方差
       ```

       运行结果：

       ```python
       1.118033988749895
       1.25
       ```

     * 排序

       * sort函数：`sort(对象, axis=-1, kind='quicksort', order=None)`

         * axis默认是-1，即沿着数组的最后一个轴进行排序。当然它的值可以指定为None，即把所有元素采用扁平化的方式作为一个向量进行排序
         * order是用于结构化数组排序中，可以按照某个字段进行排序
         * kind默认是quicksort，可以指定mergesort、heapsort等

       * 使用：

         ```python
         # 排序
         a = np.array([[4,3,2],[2,4,1]])
         print(np.sort(a)) # 即按axis = -1也就是=1来排
         print(np.sort(a, axis=None)) # 当作一个向量来排
         print(np.sort(a, axis=0))  
         print(np.sort(a, axis=1))  
         ```

         运行结果：

         ```python
         [[2 3 4]
          [1 2 4]]
         [1 2 2 3 4 4]
         [[2 3 1]
          [4 4 2]]
         [[2 3 4]
          [1 2 4]]
         ```

3. **练习**：

   * 统计全班的成绩  姓名 语文 数学 英语

     ```python
     import numpy as np
     def printScore(name, container):
         print('%s | %f | %d | %d | %f | %f' %(name, np.mean(container), np.amin(container), np.amax(container), np.var(container), np.std(container)))
         
     studenttype = np.dtype({'names' : ['name', 'chinese', 'english', 'math', 'total'], 'formats' : ['U32', 'i', 'i', 'i', 'i']}) # 中文类型不能用S32，S只支持ascii编码
     students = np.array([('张飞', 66, 65, 30, 0), ('关羽', 95, 85, 98, 0), ('赵云', 93, 92, 96, 0), ('黄忠', 90, 88, 77, 0), ('典韦', 80, 90, 90, 0)], dtype = studenttype)
     students['total'] = students['chinese'] + students['math'] + students['english']
     chinese = students['chinese']
     english = students['english']
     math = students['math']
     
     print('----------成绩统计----------')
     print('科目 | 平均成绩 | 最小成绩 | 最大成绩 | 方差 | 标准差')
     printScore('语文', chinese)
     printScore('英语', english)
     printScore('数学', math)
     print('未按总成绩排序前：%s' %students)
     print('按总成绩排序后：%s' %np.sort(students, order = 'total')[::-1]) # 按总分先从小到大排序后再反转数组
     ```

     运行结果：

     ```python
     ----------成绩统计----------
     科目 | 平均成绩 | 最小成绩 | 最大成绩 | 方差 | 标准差
     语文 | 84.800000 | 66 | 95 | 114.960000 | 10.721940
     英语 | 84.000000 | 65 | 92 | 95.600000 | 9.777525
     数学 | 78.200000 | 30 | 98 | 634.560000 | 25.190474
     未按总成绩排序前：[('张飞', 66, 65, 30, 161) ('关羽', 95, 85, 98, 278) ('赵云', 93, 92, 96, 281)
      ('黄忠', 90, 88, 77, 255) ('典韦', 80, 90, 90, 260)]
     按总成绩排序后：[('赵云', 93, 92, 96, 281) ('关羽', 95, 85, 98, 278) ('典韦', 80, 90, 90, 260)
      ('黄忠', 90, 88, 77, 255) ('张飞', 66, 65, 30, 161)]
     ```

## 5. 科学计算Pandas库

### 5.1 前言

* 为什么会用pandas？

  答：Pandas提供的基础数据结构DataFrame与json的契合度很高，转换起来就很方便。几句Pandas代码就可以解决一般的数据清理工作。

* Pandas的两个核心数据结构：Series和DataFrame，分别代表着一维的序列和二维的表结构。

### 5.2 Series

* **定义**：定长的字典序列

* **基本属性**：index和values (index如果没指定的话默认是0，1，2....)

  ```python
  from pandas import Series, DataFrame
  x1 = Series([1, 2, 3, 4]) # 默认index
  x2 = Series(data = [1, 2, 3, 4], index = ['a', 'b', 'c', 'd']) # 指定index
  print(x1)
  print(x2)
  ```

  运行结果：

  ```python
  0    1
  1    2
  2    3
  3    4
  dtype: int64
  a    1
  b    2
  c    3
  d    4
  dtype: int64
  ```

* **用字典创建Series**：

  ```python
  # 用字典创建Series
  d = {'a' : 1, 'b' : 2, 'c' : 3, 'd' : 4}
  x3 = Series(d)
  print(x3)
  ```

  运行结果：

  ```python
  a    1
  b    2
  c    3
  d    4
  dtype: int64
  ```

### 5.3 DataFrame

* **定义**：类数据库表

* **索引**：行索引和列索引

* **创建DataFrame**：

  ```python
  # 创建DataFrame
  from pandas import Series, DataFrame
  data = {'Chinese' : [66, 95, 93, 90, 80], 'English' : [65, 85, 92, 88, 90], 'Math' : [30, 98, 96, 77, 90]}
  df1 = DataFrame(data)
  print(df1)
  df2 = DataFrame(data, index = ['ZhangFei', 'GuanYu', 'ZhaoYun', 'HuangZhong', 'DianWei'], columns = ['English', 'Math', 'Chinese'])
  print(df2)
  ```

  运行结果：

  ```python
     Chinese  English  Math
  0       66       65    30
  1       95       85    98
  2       93       92    96
  3       90       88    77
  4       80       90    90
              English  Math  Chinese
  ZhangFei         65    30       66
  GuanYu           85    98       95
  ZhaoYun          92    96       93
  HuangZhong       88    77       90
  DianWei          90    90       80
  ```

### 5.4 数据导入与导出

* Pandas允许直接从xlsx，csv等文件中导入数据，也可以输出到xlsx，csv等文件。

* **例子**：

  ```python
  import pandas as pd
  from pandas import Series, DataFrame
  df1 = DataFrame(pd.read_excel('data.xlsx')) # 导入数据
  df1.to_excel('data2.xlsx') # 导出数据
  print(df1)
  ```

### 5.5 数据清洗

以下面的数据为例，演练在数据清洗过程中遇到的一般情况。

```python
data = {'Chinese': [66, 95, 93, 90,80],'English': [65, 85, 92, 88, 90],'Math': [30, 98, 96, 77, 90]}
df2 = DataFrame(data, index=['ZhangFei', 'GuanYu', 'ZhaoYun', 'HuangZhong', 'DianWei'], columns=['English', 'Math', 'Chinese'])
```

1. **删除DataFrame中不必要的列或行(drop())**

   ```python
   # 1. 删除DataFrame中不必要的列或行
   df2 = df2.drop(columns = ['Chinese']) # 删除Chinese列
   print(df2)
   df2 = df2.drop(index = ['ZhangFei']) # 删除张飞这一行
   print(df2)
   ```

   运行结果：

   ```python
               English  Math
   ZhangFei         65    30
   GuanYu           85    98
   ZhaoYun          92    96
   HuangZhong       88    77
   DianWei          90    90
               English  Math
   GuanYu           85    98
   ZhaoYun          92    96
   HuangZhong       88    77
   DianWei          90    90
   ```

2. **重命名列名columns，让列表名更容易识别(rename())**

   ```python
   # 2. 重命名列名
   df2.rename(columns = {'Math' : '数学', 'English' : '英语'}, inplace = True)
   print(df2)
   ```

   运行结果：

   ```python
              英语  数学
   GuanYu      85  98
   ZhaoYun     92  96
   HuangZhong  88  77
   DianWei     90  90
   ```

3. **去除重复值(drop_duplicates())**

   ```python
   # 3. 去除重复值
   df = df.drop_duplicates() # 去掉重复行
   ```

4. **格式问题**

   * 更改数据格式：规范数据格式`astype()`

   ```python
   import numpy as np
   # 4. 更改数据格式
   df2['数学'].astype('str') # 把数学字段的值改成str类型
   df2['英语'].astype(np.int64) # 把英语字段的值改成int64
   ```

   * 数据间空格：使用strip函数删除数据间空格(该列的数据类型须是str类型，可以用astype进行转换)

   ```python
   # 删除左右两边空格
   df2['数学'] = df2['数学'].map(str.strip)
   # 删除左边空格
   df2['数学'] = df2['数学'].map(str.lstrip)
   # 删除右边空格
   df2['数学'] = df2['数学'].map(str.rstrip)
   ```

   * 删掉某个符号：如删掉美元符号

   ```python
   df2['数学'] = df2['数学'].str.strip('$') 
   ```

   * 大小写转换：upper()，lower()，title()

   ```python
   # 大小写转换
   # 全部大写
   df2.columns = df2.columns.str.upper()
   # 全部小写
   df2.columns = df2.columns.str.lower()
   # 首字母大写
   df2.columns = df2.columns.str.title()
   print(df2)
   ```

   * 查找空值：isnull()

   ```python
   from numpy import nan 
   data = {'姓名' : ['张飞', '关羽', '赵云', '黄忠', '典韦'], '语文' : [66, 95, 95, 90, 80], '英语' : [65, 85, 92, 88, 90], '数学' : [nan, 98, 96, 77, 90]}
   df = DataFrame(data = data, columns = ['姓名', '语文', '英语', '数学'])
   print(df)
   print(df.isnull()) # 查看哪个地方存在空值
   print(df.isnull().any()) # 查看哪些列存在空值
   ```

   运行结果：

   ```python
      姓名  语文  英语    数学
   0  张飞  66  65   NaN
   1  关羽  95  85  98.0
   2  赵云  95  92  96.0
   3  黄忠  90  88  77.0
   4  典韦  80  90  90.0
         姓名     语文     英语     数学
   0  False  False  False   True
   1  False  False  False  False
   2  False  False  False  False
   3  False  False  False  False
   4  False  False  False  False
   姓名    False
   语文    False
   英语    False
   数学     True
   dtype: bool
   ```

   * 数据清洗函数apply：一个自由度非常高，使用频率也高的函数

     * 对某一列进行大小写转换：

       ```python
       df['姓名'] = df['姓名'].apply(str.upper) # 对姓名列进行大小写转换
       ```

     * 将原来某列数值进行操作后返回：

       ```python
       def double_df(x):
           return 2 * x
       df['语文'] = df['语文'].apply(double_df) # 将语文成绩*2后返回
       print(df)
       ```

       运行结果：

       ```python
         姓名   语文  英语    数学
       0  张飞  132  65   NaN
       1  关羽  190  85  98.0
       2  赵云  190  92  96.0
       3  黄忠  180  88  77.0
       4  典韦  160  90  90.0
       ```

     * 定义更复杂的函数使用apply应用： 新增两列，其中new1列是“语文”和“英语”成绩之和的 m 倍，new2列是“语文”和“数学”成绩之和的 n 倍 

       ```python
       def plus(df, n, m):
           df['new1'] = (df['语文'] + df['英语']) * m
           df['new2'] = (df['语文'] + df['数学']) * n
           return df
       df = df.apply(plus, axis = 1, args = (2, 3)) # axis = 1代表按列为轴进行操作，args是传递的两个参数
       print(df)
       ```

       运行结果：

       ```python
          姓名   语文  英语    数学  new1   new2
       0  张飞  132  65   NaN   591    NaN
       1  关羽  190  85  98.0   825  576.0
       2  赵云  190  92  96.0   846  572.0
       3  黄忠  180  88  77.0   804  514.0
       4  典韦  160  90  90.0   750  500.0
       ```

### 5.6 数据统计

* 和NumPy一样，都有常用的统计函数，如果遇到空值NaN，会自动排除。

* 常用的统计函数有：

  | 函数       | 作用                                                       |
  | ---------- | ---------------------------------------------------------- |
  | count()    | 统计个数，空值NaN不算                                      |
  | describe() | 一次性输出多个统计指标，包括：count，mean，std，min，max等 |
  | min()      | 最小值                                                     |
  | max()      | 最大值                                                     |
  | sum()      | 总和                                                       |
  | mean()     | 平均值                                                     |
  | median()   | 中位数                                                     |
  | var()      | 方差                                                       |
  | std()      | 标准差                                                     |
  | argmin()   | 统计最小值的索引位置                                       |
  | argmax()   | 统计最大值的索引位置                                       |
  | idxmin()   | 统计最小值的索引值                                         |
  | idxmax()   | 统计最大值的索引值                                         |

* describe()函数测试：

  ```python
  df1 = DataFrame({'name' : ['ZhangFei', 'GuanYu', 'a', 'b', 'c'], 'data1' : range(5)})
  print(df1.describe())
  ```

  运行结果：

  ```python
            data1
  count  5.000000
  mean   2.000000
  std    1.581139
  min    0.000000
  25%    1.000000
  50%    2.000000
  75%    3.000000
  max    4.000000
  ```


### 5.7 数据表合并

* 创建两个DataFrame：

  ```python
  from pandas import DataFrame
  import pandas as pd
  df1 = DataFrame({'name':['ZhangFei', 'GuanYu', 'a', 'b', 'c'], 'data1':range(5)})
  df2 = DataFrame({'name':['ZhangFei', 'GuanYu', 'A', 'B', 'C'], 'data2':range(5)})
  ```

1. 基于指定列进行连接

   ```python
   # 1. 基于指定列进行连接
   df3 = pd.merge(df1, df2, on = 'name')
   print(df3)
   ```

   运行结果：

   ```python
          name  data1  data2
   0  ZhangFei      0      0
   1    GuanYu      1      1
   ```

2. inner内连接(merge合并的默认情况)

   ```python
   df3 = pd.merge(df1, df2, how = 'inner') # 自动找键的交集
   print(df3)
   ```

   运行结果：

   ```python
          name  data1  data2
   0  ZhangFei      0      0
   1    GuanYu      1      1
   ```

3. left左连接

   ```python
   # 3. 左连接
   df3 = pd.merge(df1, df2, how = 'left')
   print(df3)
   ```

   运行结果：

   ```python
          name  data1  data2
   0  ZhangFei      0    0.0
   1    GuanYu      1    1.0
   2         a      2    NaN
   3         b      3    NaN
   4         c      4    NaN
   ```

4. right右连接

   ```python
   # 4. 右连接
   df3 = pd.merge(df1, df2, how = 'right')
   print(df3)
   ```

   运行结果：

   ```python
          name  data1  data2
   0  ZhangFei    0.0      0
   1    GuanYu    1.0      1
   2         A    NaN      2
   3         B    NaN      3
   4         C    NaN      4
   ```

5. outer外连接

   ```python
   # 5. 外连接
   df3 = pd.merge(df1, df2, how = 'outer')
   print(df3)
   ```

   运行结果：

   ```python
          name  data1  data2
   0  ZhangFei    0.0    0.0
   1    GuanYu    1.0    1.0
   2         a    2.0    NaN
   3         b    3.0    NaN
   4         c    4.0    NaN
   5         A    NaN    2.0
   6         B    NaN    3.0
   7         C    NaN    4.0
   ```

### 5.8 使用SQL方式打开Pandas

* 用到的工具：`pandasql`

  用到工具中的主要函数`sqldf`，它接收两个参数：一个SQL查询语句，还有一组环境变量globals()或locals()

* 示例：

  ```python
  # 使用SQL方式操作Pandas
  import pandas as pd
  from pandas import DataFrame
  from pandasql import sqldf, load_meat, load_births
  df1 = DataFrame({'name' : ['ZhangFei', 'GuanYu', 'a', 'b', 'c'], 'data1' : range(5)})
  pysqldf = lambda sql : sqldf(sql, globals()) # lambda是用来定义一个匿名函数，使用globals是因为在sql中有对全局参数df1的使用
  sql = "select * from df1 where name = 'ZhangFei'"
  print(pysqldf(sql))
  ```

  运行结果：

  ```python
         name  data1
  0  ZhangFei      0
  ```

### 5.9 练习

* 对下面数据进行清洗，同时新增一列总和，计算每个人三科总和

  ```python
  from numpy import nan
  df = DataFrame({'姓名' : ['张飞', '关羽', '赵云', '黄忠', '典韦', '典韦'], '语文' : [66, 95, 95, 90, 80, 80], '英语' : [65, 85, 92, 88, 90, 90], '数学' : [nan, 98, 96, 77, 90, 90]})
  ```

  解决代码：

  ```python
  # print(df)
  df = df.drop_duplicates() # 去除重复行
  df['数学'].fillna(df['数学'].mean(), inplace = True) # 填充值
  df['总和'] = df.sum(axis = 1) # 求总和
  print(df) # 输出处理后的表
  ```

  运行结果：

  ```python
     姓名  语文  英语     数学      总和
  0  张飞  66  65  90.25  221.25
  1  关羽  95  85  98.00  278.00
  2  赵云  95  92  96.00  283.00
  3  黄忠  90  88  77.00  255.00
  4  典韦  80  90  90.00  260.00
  ```

## 6. 需要掌握的基本概念

### 6.1 商业智能BI、数据仓库DW、数据挖掘DM三者之间的关系

* **商业智能**：英文是Business Intelligence，是基于数据仓库，经过了数据挖掘后，得到了商业价值的过程。
* **数据仓库**：英文是Data Warehouse，是BI的地基，搭建好DW这个地基之后，才能进行分析使用，最后产生价值。
* **数据挖掘**：英文是Data Mining，是一门炼金术，通过它，我们可以从数据仓库中得到宝藏，比如商业报告。其核心包括分类、聚类、预测、关联分析等。

### 6.2 元数据VS数据元

* **元数据**：MetaData，描述其他数据的数据，也称为“中介数据”，可以帮助我们方便的管理数据仓库
* **数据元**：Data Element，最小的数据单元

### 6.3 数据挖掘的流程

Knowledge Discovery in Database，简称KDD

1. **分类**：通过训练集得到一个分类模型，然后用这个模型对其他数据进行分类
2. **聚类**：将数据自动聚成几个类别
3. **预测**：通过当前和历史数据预测未来趋势
4. **关联分析**：发现数据中的关联规则(被广泛应用在购物栏分析)

完整的知识发现过程就是：

输入数据--》数据预处理(特征选择、维规约、规范化、选择数据子集)--》数据挖掘--》后处理(模式过滤、可视化、模式表示)--》信息

数据后处理是将模型预测的结果进一步处理后再导出

### 6.4 数据预处理的几个步骤

数据预处理的目的：将数据转化成我们需要的格式。

1. **数据清洗**：去除重复数据，去噪声(即干扰数据)以及填充缺失值
2. **数据集成**：将多个数据源中的数据存放在一个统一的数据存储中
3. **数据变换**：将数据转换成适合数据挖掘的形式

## 7. 用户画像

### 7.1 用户画像的准则

解决的三个问题：

1. 用户从哪里来？
2. 这些用户是谁？
3. 这些用户要到哪里去？

用户画像建模的三个步骤(也称准则)：

1. 统一用户的唯一标识(统一化)[<font color = red>用户画像的核心</font>]
2. 给用户打标签，即用户画像(标签化)
3. 将用户画像，指导业务关联(业务化)

标签划分八字(用户消费行为分析)：

* 用户标签：年龄、性别、职业、学历等
* 消费标签：消费习惯、购买意向、是否对促销敏感等
* 行为标签：时间段、频次、时长、访问路径
* 内容分析：对用户平时浏览的内容，尤其是停留时间长、浏览次数多的内容进行分析

有了用户画像，可以为企业带来业务价值。从用户生命周期的三个阶段划分业务价值：

1. 获客：如何进行拉新，通过更精准的营销获取客户
2. 粘客：个性化推荐，搜索排序，场景运营等
3. 留客：流失率预测，分析关键节点降低流失率

按照数据流处理阶段来划分用户画像建模过程：

1. 数据层：用户消费行为里的标签。在这一层，我们可以打上“事实标签”，作为数据客观的记录
2. 算法层：透过这些行为算出的用户建模。在这一层，打上“模型标签“，作为用户画像的分类标识
3. 业务层：获客、粘客、留客的手段。在这一层，打上“预测标签”，作为业务关联的结果

整个标签化的流程就是通过数据层的“事实标签”，在算法层进行计算，打上“模型标签”的分类结果，最后指导业务层，得出“预测标签”。

### 7.2 美团外卖的用户画像

1. 使用手机号作为用户的唯一标识
2. 按照“用户消费行为分析”准则设计标签：
   * 用户标签：性别、年龄、家乡、通过何种渠道进行的注册等
   * 消费标签：餐饮口味、消费均价、团购等级、预定使用等级、排队使用等级、外卖等级
   * 行为标签：点外卖时间段、使用频次、平均点餐用时、访问路径等
   * 内容分析：基于用户平时浏览的内容进行统计，包括餐饮口味、优惠敏感度等
3. 基于标签，产生业务价值：
   * **在获客上**，找到优势的宣传渠道，吸引潜在有需求的用户，刺激其转化
   * **在粘客上**，如何提升用户的消费频次和单价，方法可以包括购买后的个性化推荐、针对优质用户进行优质高价商品的推荐、以及重复购买，比如通过红包、优惠等方式激励对优惠敏感的人群，提升购买频次
   * **在留客上**，预测用户是否可能会从平台上流失，降低用户留存的运营成本

## 8 数据采集

### 8.1 数据源分类

1. **开放数据源**：政府、企业、高校
2. **爬虫抓取**：网页、app
3. **日志采集**：前端采集、后端脚本
4. **传感器**：图像、测速、热敏

### 8.2 爬虫采集数据流程

1. 使用Requests抓取网页信息
2. 使用XPath(XML_Path)解析内容
3. 使用Pandas保存数据，最后再写入到xls或MySQL等数据库中

**不自己编程抓取网页的工具**：

* <a href="http://www.locoy.com/">火车采集器</a>
* <a href="https://www.bazhuayu.com/">八爪鱼</a>
* <a href="http://www.gooseeker.com/">集搜客</a>

### 8.3 日志采集

* **日志采集两种形式**：
  1. 通过Web服务器采集，例如httpd，Nginx、Tomcat都自带日志记录功能
  2. 自定义采集用户行为，例如用JavaScript代码监听用户行为、AJAX异步请求后台记录日志等

* **埋点**：在有需要的位置采集相应的信息，进行上报(<font color = red>日志采集的关键步骤</font>)
* 埋点的本质就是在我们需要的位置植入统计代码，对于这类代码，如果不是核心需求的话，可以使用第三方统计工具，否则就自己编写。